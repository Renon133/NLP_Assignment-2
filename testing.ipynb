{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "\n",
    "from tokenizers import SentencePieceBPETokenizer, normalizers, decoders\n",
    "from tokenizers.normalizers import Replace\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 82656768\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "config.n_head = 8\n",
    "config.n_layer = 8\n",
    "config.vocab_size = 32768\n",
    "config.n_embd = 768\n",
    "\n",
    "model = AutoModelForCausalLM.from_config(config=config)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = torch.load(\"Archive 2/X_train.pt\"), torch.load(\"Archive 2/Y_train.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(32768, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-7): 8 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([44789637, 22]), torch.Size([44789637]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the path for saving model checkpoints\n",
    "checkpoint_dir = './model_checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "optim = AdamW(model.parameters(), lr=0.01)\n",
    "batch_size = 32\n",
    "train_size = len(X)\n",
    "logging_interval = 0.1\n",
    "total_loss = 0\n",
    "\n",
    "for epoch in range(5):\n",
    "    epoch_loss = np.array([])\n",
    "    model.train()  # Ensure the model is in training mode\n",
    "\n",
    "    for iter in range(0, train_size, batch_size):\n",
    "        x = X[iter: iter + batch_size]\n",
    "        y = Y[iter: iter + batch_size]\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Ensure y is a 1D tensor\n",
    "        y = y.squeeze()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(x)\n",
    "        loss = torch.nn.functional.cross_entropy(y_pred.logits[:, -1, :], y)\n",
    "        # print(loss)\n",
    "\n",
    "        # Accumulate the loss for logging\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Zero out gradients, backpropagate, and update weights\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        # Track epoch loss\n",
    "        epoch_loss = np.append(epoch_loss, loss.item())\n",
    "\n",
    "        # Log perplexity at specified intervals #TODO Its wrong correct this\n",
    "        if iter % int(train_size * logging_interval) == 0 and iter != 0:\n",
    "            avg_loss = total_loss / ((iter // batch_size) + 1)\n",
    "            perplexity = torch.exp(torch.tensor(avg_loss))\n",
    "            print(f\"Perplexity at epoch {epoch + 1}, step {iter}: {perplexity.item()}\")\n",
    "\n",
    "    # Save checkpoint after each epoch\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch + 1}.pth')\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optim.state_dict(),\n",
    "        'loss': epoch_loss.mean()\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "    print(f\"Loss of epoch {epoch + 1}: {epoch_loss.mean()}\")\n",
    "    total_loss = 0  # Reset total_loss after each epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
