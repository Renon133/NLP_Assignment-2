{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import glob\n",
    "# import re\n",
    "\n",
    "# from tokenizers import SentencePieceBPETokenizer, normalizers, decoders\n",
    "# from tokenizers.normalizers import Replace\n",
    "\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 23623680\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "config.n_head = 6\n",
    "config.n_layer = 6\n",
    "config.vocab_size = 32768\n",
    "config.n_embd = 384\n",
    "config.n_ctx = 768\n",
    "\n",
    "model = AutoModelForCausalLM.from_config(config=config)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "\n",
    "# # Replace 'path/to/your/file.zip' with your actual zip file path\n",
    "# with zipfile.ZipFile('Archive 2.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('train')  # Specify the directory to extract to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = torch.load('train/X_train.pt'), torch.load(\"train/Y_train.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X[:6398519]\n",
    "# Y = Y[:6398519]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import AdamW\n",
    "# import torch\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# # Define the path for saving model checkpoints\n",
    "# checkpoint_dir = './model_checkpoints'\n",
    "# os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# optim = AdamW(model.parameters(), lr=0.01)\n",
    "# batch_size = 1024\n",
    "# train_size = len(X)\n",
    "# logging_interval = 0.1\n",
    "# total_loss = 0\n",
    "\n",
    "# perplexity_list = np.array([])\n",
    "# final_loss = np.array([])\n",
    "# steps_per_epochs = len(range(0, train_size, batch_size))\n",
    "# logging_step = int(steps_per_epochs * logging_interval)\n",
    "\n",
    "# for epoch in range(5):\n",
    "#     epoch_loss = np.array([])\n",
    "#     model.train()  # Ensure the model is in training mode\n",
    "\n",
    "#     for idx, iter in enumerate(range(0, train_size, batch_size)):\n",
    "#         x = X[iter: iter + batch_size]\n",
    "#         y = Y[iter: iter + batch_size]\n",
    "#         x, y = x.to(device), y.to(device)\n",
    "\n",
    "#         # Ensure y is a 1D tensor\n",
    "#         y = y.squeeze()\n",
    "\n",
    "#         # Forward pass\n",
    "#         y_pred = model(x)\n",
    "#         loss = torch.nn.functional.cross_entropy(y_pred.logits[:, -1, :], y)\n",
    "\n",
    "#         # Accumulate the loss for logging\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#         # Zero out gradients, backpropagate, and update weights\n",
    "#         optim.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optim.step()\n",
    "\n",
    "#         # Track epoch loss\n",
    "#         epoch_loss = np.append(epoch_loss, loss.item())\n",
    "\n",
    "#         # Log perplexity at specified intervals\n",
    "#         if idx % logging_step == 0 and idx != 0:\n",
    "#             avg_loss = total_loss / ((iter // batch_size) + 1)\n",
    "#             perplexity = torch.exp(torch.tensor(avg_loss))\n",
    "#             perplexity_list = np.append(perplexity_list, perplexity)\n",
    "#             print(f\"Perplexity at epoch {epoch + 1}, step {iter}: {perplexity.item()}\")\n",
    "\n",
    "#     # Save checkpoint after each epoch\n",
    "#     checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch + 1}.pth')\n",
    "#     torch.save({\n",
    "#         'epoch': epoch + 1,\n",
    "#         'model_state_dict': model.state_dict(),\n",
    "#         'optimizer_state_dict': optim.state_dict(),\n",
    "#         'loss': epoch_loss.mean()\n",
    "#     }, checkpoint_path)\n",
    "#     print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "#     print(f\"Loss of epoch {epoch + 1}: {epoch_loss.mean()}\")\n",
    "#     total_loss = 0  # Reset total_loss after each epoch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 23623680\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "config.n_head = 6\n",
    "config.n_layer = 6\n",
    "config.vocab_size = 32768\n",
    "config.n_embd = 384\n",
    "config.n_ctx = 768\n",
    "\n",
    "model = AutoModelForCausalLM.from_config(config=config)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4k/xxxy9tg127s6hyrvg1srwct00000gn/T/ipykernel_33530/2911908019.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(checkpoint_path,map_location=torch.device('mps'))['model_state_dict'])\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import SentencePieceBPETokenizer\n",
    "\n",
    "checkpoint_path = './Model/model_epoch_5.pth'\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path,map_location=torch.device('mps'))['model_state_dict'])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Move the model to the device (CPU or GPU)\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "tokenizer = SentencePieceBPETokenizer(\n",
    "    \"./Tokenizer/my_tokenizer_1-vocab.json\",\n",
    "    \"./Tokenizer/my_tokenizer_1-merges.txt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[622, 1531, 185, 4003, 3503, 10801]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Example test input (should be tokenized and preprocessed)\n",
    "test_input = \"તમારા ઘર માટે યુગાદી શણગાર\"\n",
    "encoded_input = tokenizer.encode(test_input)\n",
    "encoded_input.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  622,  1531,   185,  4003,  3503, 10801], device='mps:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.Tensor(encoded_input.ids).to(device='mps', dtype=torch.long)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    try:\n",
    "        output = model(input_ids)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during generation: {e}\")\n",
    "        exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = output.logits\n",
    "predicted_token_ids = torch.argmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'જ પર પરરનીરની '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(predicted_token_ids.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 32768])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New token: જ પર પરરનીરની \n",
      "Appended Input: તમારા ઘર માટે યુગાદી શણગારજ પર પરરનીરની \n",
      "\n",
      "New token: જ પર પરરનીરની       \n",
      "Appended Input: તમારા ઘર માટે યુગાદી શણગારજ પર પરરનીરની જ પર પરરનીરની       \n",
      "\n",
      "New token: જ પર પરરનીરની                  \n",
      "Appended Input: તમારા ઘર માટે યુગાદી શણગારજ પર પરરનીરની જ પર પરરનીરની       જ પર પરરનીરની                  \n",
      "\n",
      "New token: જ પર પરરનીરની                                        \n",
      "Appended Input: તમારા ઘર માટે યુગાદી શણગારજ પર પરરનીરની જ પર પરરનીરની       જ પર પરરનીરની                  જ પર પરરનીરની                                        \n",
      "\n",
      "New token: જ પર પરરનીરની                                                                                    \n",
      "Appended Input: તમારા ઘર માટે યુગાદી શણગારજ પર પરરનીરની જ પર પરરનીરની       જ પર પરરનીરની                  જ પર પરરનીરની                                        જ પર પરરનીરની                                                                                    \n",
      "\n",
      "New token: જ પર પરરનીરની                                                                                                                                                                            \n",
      "Appended Input: તમારા ઘર માટે યુગાદી શણગારજ પર પરરનીરની જ પર પરરનીરની       જ પર પરરનીરની                  જ પર પરરનીરની                                        જ પર પરરનીરની                                                                                    જ પર પરરનીરની                                                                                                                                                                            \n",
      "\n",
      "New token: જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                            \n",
      "Appended Input: તમારા ઘર માટે યુગાદી શણગારજ પર પરરનીરની જ પર પરરનીરની       જ પર પરરનીરની                  જ પર પરરનીરની                                        જ પર પરરનીરની                                                                                    જ પર પરરનીરની                                                                                                                                                                            જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                            \n",
      "\n",
      "New token: જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "Appended Input: તમારા ઘર માટે યુગાદી શણગારજ પર પરરનીરની જ પર પરરનીરની       જ પર પરરનીરની                  જ પર પરરનીરની                                        જ પર પરરનીરની                                                                                    જ પર પરરનીરની                                                                                                                                                                            જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                            જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "\n",
      "New token: જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "Appended Input: તમારા ઘર માટે યુગાદી શણગારજ પર પરરનીરની જ પર પરરનીરની       જ પર પરરનીરની                  જ પર પરરનીરની                                        જ પર પરરનીરની                                                                                    જ પર પરરનીરની                                                                                                                                                                            જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                            જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "\n",
      "New token: જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "Appended Input: તમારા ઘર માટે યુગાદી શણગારજ પર પરરનીરની જ પર પરરનીરની       જ પર પરરનીરની                  જ પર પરરનીરની                                        જ પર પરરનીરની                                                                                    જ પર પરરનીરની                                                                                                                                                                            જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                            જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            જ પર પરરનીરની                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming `logits` is the output from the model after running inference\n",
    "# and contains logits for the current sequence.\n",
    "logits = output.logits\n",
    "\n",
    "# Step 1: Extract the logits for the last token in the sequence\n",
    "current_input_ids = input_ids[0].tolist()  # Start with the original input\n",
    "\n",
    "# Step 2: Loop to generate 10 tokens sequentially\n",
    "input_tokens = \"તમારા ઘર માટે યુગાદી શણગાર\"\n",
    "output_token = \"\"\n",
    "for _ in range(10):\n",
    "    input = torch.Tensor(tokenizer.encode(input_tokens + output_token).ids).to(device, dtype = torch.long)\n",
    "    with torch.no_grad():\n",
    "        output = model(input)\n",
    "        logits = output.logits\n",
    "        predicted_token_ids = torch.argmax(logits, dim=-1)\n",
    "        input_tokens += output_token\n",
    "        output_token = tokenizer.decode(predicted_token_ids.tolist())\n",
    "    print(\"New token:\", output_token)\n",
    "    print(\"Appended Input:\", input_tokens + output_token, end='\\n\\n')\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
